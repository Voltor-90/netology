# netology-virt-01-basics
Домашнее задание. Введение в Виртуализацию.
---
Задание 1. Ознакомился с Yandex.Cloud
---
Задание 2.
---
Задача 1: Высоконагруженная база данных MySql, критичная к отказу
	Что важно: Максимальная производительность диска и памяти, минимальные задержки. Отказоустойчивость (чтобы при проблемах служба не падала).
	Выбор: Физические сервера или специальные решения для паравиртуализации.
	Объяснение: Для максимальной скорости часто выбирают физические серверы. Но для отказоустойчивости их нужно минимум два + настройка репликации. Современная паравиртуализация (с пас-through дисками и т.п.) тоже подходит и даёт больше гибкости для резервного копирования и миграции. Виртуализация уровня ОС — не лучший выбор, так как СУБД очень чувствительна к ресурсам и изоляции.

Задача 2: Различные web-приложения
	Что важно: Гибкость, быстрый запуск, экономия ресурсов, лёгкое масштабирование.
	Выбор: Виртуализация уровня ОС (контейнеры).
	Объяснение: Это идеальный сценарий для контейнеров (Docker). Приложения (например, на Python, Node.js, Java) быстро упаковываются, легко запускаются в любом месте и экономно используют общие ресурсы. Можно запустить десятки контейнеров на одном сервере. Паравиртуализация тоже подойдёт, но будет менее эффективна по ресурсам.

Задача 3: Windows-системы для использования бухгалтерским отделом
	Что важно: Изоляция, работа с ОС Windows, часто — интеграция с 	Active Directory, безопасность.
	Выбор: Паравиртуализация.
	Объяснение: Гипервизор (VMware, Hyper-V) создаст отдельные виртуальные машины с Windows для пользователей или служб. Это даст полную изоляцию, знакомую среду Windows для бухгалтерии и удобное централизованное управление. Физические сервера будут неэкономичны (один сервер на пару пользователей). Виртуализация уровня ОС с Windows не работает (или работает очень плохо в виде исключения).

Задача 4: Системы, выполняющие высокопроизводительные расчёты на GPU
	Что важно: Прямой и полный доступ к «железу», особенно к видеокартам (GPU), для научных или инженерных расчётов (например, для ИИ, рендеринга).
	Выбор: Физические сервера.
	Объяснение: Для таких задач нужно, чтобы приложение напрямую «общалось» с GPU, без любых посредников. Виртуализация (особенно с GPU) возможна, но сложна в настройке, дорога и часто ведёт к потере производительности. Поэтому стандартный выбор — мощный физический сервер с несколькими GPU, выделенный только под эту задачу.

Задание 3.
---
Сценарий 1: 100 виртуальных машин на базе Linux и Windows, общие задачи, нет особых требований. Преимущественно Windows based-инфраструктура, требуется реализация программных балансировщиков нагрузки, репликации данных и автоматизированного механизма создания резервных копий.
	Выбор: VMware vSphere.
	Объяснение: Готовый коробочный продукт для таких задач. Стандарт отрасли. Но дорогой.

Сценарий 2: Требуется наиболее производительное бесплатное open source-решение для виртуализации небольшой (20-30 серверов) инфраструктуры на базе Linux и Windows виртуальных машин.
	Выбор: Proxmox VE.
	Объяснение: Готовый, бесплатный дистрибутив на базе Debian, который включает KVM, удобный веб-интерфейс, встроенные механизмы репликации и бэкапов. Это оптимальный баланс производительности, функциональности и простоты для инфраструктуры такого масштаба.

Сценарий 3: Необходимо бесплатное, максимально совместимое и производительное решение для виртуализации Windows-инфраструктуры.
	Выбор: Microsoft Hyper-V Server (бесплатный) или Hyper-V роль в Windows Server (бесплатна как роль).
	Объяснение: Ничего не будет совместимее с Windows, чем продукт самой Microsoft. Hyper-V Server — это отдельный бесплатный гипервизор от Microsoft (только ядро, без GUI). Или можно установить Windows Server и добавить роль Hyper-V. Это гарантирует поддержку всех фич Windows (гостевое обновление Integration Services, работа с Active Directory), лучшую производительность драйверов и минимум проблем с лицензированием Windows внутри ВМ.

Сценарий 4: Необходимо рабочее окружение для тестирования программного продукта на нескольких дистрибутивах Linux.
	Выбор: Oracle VirtualBox(бесплатный) или VMware Workstation Player(платный для комерческого использования)
	Объяснение: Это не серверный, а десктопный сценарий. Нужен гипервизор, который ставится на Windows, Linux или macOS. VirtualBox — полностью бесплатен, кроссплатформенен, идеален для тестовых стендов. VMware Workstation Player — тоже отличный вариант, чуть лучше производительность и интеграция с хостом. Они созданы именно для таких задач на одном компьютере.

Задание 4.
---
Проблемы и недостатки гетерогенной среды

1. Сложность и стоимость администрирования
	Проблема: Администраторам нужно знать не одну, а несколько сложных систем. Разные интерфейсы, разные логики работы, разные команды CLI.
	Пример: Чтобы перенести ВМ или сделать снапшот, в VMware vSphere, Hyper-V и Proxmox VE — три абсолютно разных алгоритма действий.
	Последствие: Требуется больше высокооплачиваемых специалистов или много времени на обучение. Увеличивается риск человеческой ошибки.
2. Несовместимость инструментов и форматов
	Проблема: У каждого гипервизора свой собственный формат виртуальных дисков (VMDK у VMware, VHD/VHDX у Hyper-V, QCOW2/RAW у KVM). Свои форматы снапшотов, конфигураций ВМ.
	Пример: Нельзя просто взять виртуальную машину из VMware и запустить её на Hyper-V. Нужна конвертация, которая не всегда проходит гладко и может занять много времени.
	Последствие: Сложности при миграции, аварийном восстановлении, тестировании. Невозможность создать единый процесс.
3. Высокие совокупные затраты на лицензирование (TCO)
	Проблема: За лицензии, поддержку и обучение по нескольким платным системам (VMware, Windows Server для Hyper-V) придётся платить больше.
	Пример: Даже если одна среда на бесплатном KVM, а другая на платном VMware — затраты на администрирование и интеграцию всё равно суммируются.
	Последствие: Общая стоимость владения (TCO) оказывается выше, чем в гомогенной среде.
4. Фрагментация ресурсов и неэффективное их использование
	Проблема: Ресурсы железа (кластеры серверов, системы хранения) делятся между разными платформами. Их сложно перераспределить оперативно.
	Пример: В кластере VMware нехватка памяти, а в кластере Hyper-V — простаивающие мощные серверы. Быстро "одолжить" ресурсы нельзя.
	Последствие: Падает общая эффективность использования железа (utilization rate), требуется избыточное резервирование.
5. Сложность реализации единой политики безопасности и резервного копирования
	Проблема: Для каждой платформы нужны отдельные агенты, плагины и политики в системах резервного копирования, мониторинга и информационной безопасности.
	Пример: Нужно покупать и настраивать разные модули для Veeam/Bacula, чтобы они работали с VMware И с KVM.
	Последствие: Усложняется аудит, возрастает риск "слепых зон" в безопасности, процесс бэкапа становится ненадёжным.
6. Проблемы с поддержкой от вендоров
	Проблема: При возникновении сложной проблемы, вендоры будут винить "стороннее ПО" и снимать с себя ответственность.
	Пример: Сетевая проблема между ВМ на разных гипервизорах. VMware скажет "мы работаем только в своей среде", производитель сетевого оборудования — "обращайтесь к вендору гипервизора".
	Последствие: Время на решение инцидентов (MTTR) резко увеличивается.
Как минимизировать риски, если гетерогенность неизбежна?

Если выбора нет (наследие, специфические требования), можно снизить градус проблем:
	
	Стандартизация и сегрегация (разделение)
	Что делать: Чётко разделить зоны ответственности. Например: "VMware — для критичной основной инфраструктуры, Hyper-V — только для рабочих мест бухгалтерии, KVM/Proxmox — для DevOps-стендов". И не смешивать их на одном физическом железе.
	Зачем: Упрощает администрирование и делает границы проблем понятными.
	Автоматизация и оркестрация через единый пункт управления
	Что делать: Использовать платформы оркестрации более высокого уровня, которые умеют работать с разными гипервизорами. Например, Terraform для создания инфраструктуры, Ansible для конфигурации, vRealize Automation или OpenStack (если есть экспертиза).
	Зачем: Администратор работает с одним инструментом (Ansible playbook), который "за кулисами" управляет ВМ на разных платформах.
	Унификация операций
	Что делать: Создать единые регламенты и скрипты для рутинных операций (резервное копирование, мониторинг, обновление), которые будут абстрагированы от конкретного гипервизора.
	Зачем: Снижает операционные риски и нагрузку на админов.
	Выбор и консолидация систем управления
	Что делать: Внедрить единые системы мониторинга (Zabbix, Prometheus с нужными экспортерами) и резервного копирования (Veeam, который поддерживает несколько гипервизоров), даже если для этого потребуются дополнительные лицензии.
	Зачем: Даёт целостную картину и контроль над всей средой.
	Постепенная конвергенция (долгосрочная стратегия)
	Что делать: Разработать план постепенного переноса (миграции) нагрузок с менее критичных или устаревших платформ на одну основную.
	Зачем: Стратегическая цель — всё-таки прийти к гомогенной среде, снизив затраты и сложность.

Личное мнение: создавать ли гетерогенную среду с нуля?
	
	Однозначно НЕТ, если есть выбор.
	Для 99% организаций (особенно средних и небольших) выгоды от гетерогенности (мифическая "независимость от вендора", "лучший инструмент для каждой задачи") не перевешивают колоссальных операционных сложностей и затрат.
	Исключения, где это может быть оправдано:
	Очень крупные компании или облачные провайдеры, где разные команды работают абсолютно изолированно, а масштаб позволяет содержать несколько экспертных групп.
	Специфические задачи, где одна платформа физически не поддерживает нужное железо или ПО (например, GPU-пасинг лучше в KVM, а legacy-приложение требует старый Hyper-V).
	Политика "лучший инструмент для задачи" в ультра-нишевых сценариях (например, стенд для тестирования гипервизоров).